{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68059c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dbe41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Desc: Basic preprocessing function\n",
    "Input: f (string) - file name\n",
    "Output: Cleaned csv file saved to clean_data folder\n",
    "        and prints basic statistics to console\n",
    "\"\"\"\n",
    "def basic_data_preproc(f):\n",
    "    \n",
    "    try:\n",
    "        # Load submissions\n",
    "        df = pd.read_csv(f, \n",
    "                         usecols = ['id', 'author', 'created_utc', 'link_flair_text', 'num_comments',\n",
    "                                    'score', 'selftext', 'subreddit', 'title', 'total_awards_received'])\n",
    "\n",
    "        # Remove rows with deleted authors and deleted/removed selftext\n",
    "        df = df[df['author'] != \"[deleted]\"]\n",
    "        df = df[df['selftext'] != \"[deleted]\"]\n",
    "        df = df[df['selftext'] != \"[removed]\"]\n",
    "\n",
    "        # Keep rows in created_utc if it is int\n",
    "        df = df.loc[df['created_utc'].apply(type) == int]\n",
    "\n",
    "        # Replace NaNs in selftext, title, and link_flair with empty string\n",
    "        df['selftext'] = df['selftext'].fillna(\"\")\n",
    "        df['title'] = df['title'].fillna(\"\")\n",
    "        df['link_flair_text'] = df['link_flair_text'].fillna(\"\")\n",
    "\n",
    "        # Replace NaNs in total_awards_received with 0\n",
    "        df['total_awards_received'] = df['total_awards_received'].fillna(0)\n",
    "\n",
    "        # Check how many are 0 in total awards received and the percentage\n",
    "        print(\"Number of total awards = 0:\", len(df[df['total_awards_received'] == 0]))\n",
    "        print(\"Percentage of total awards = 0:\",\n",
    "              len(df[df['total_awards_received'] == 0])/len(df.index))\n",
    "\n",
    "        # Convert created_utc to date (DD/MM/YYYY)\n",
    "        df['date'] = pd.to_datetime(df['created_utc'], unit='s').dt.strftime('%d/%m/%Y')\n",
    "\n",
    "        # Concatenate title and selftext column together\n",
    "        df['text'] = df['title'] + \" \" + df['selftext']\n",
    "\n",
    "        # Remove rows where text is empty\n",
    "        df = df[df['text'] != \"\"]\n",
    "\n",
    "        # Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Select columns to keep and reorder them\n",
    "        df = df[['subreddit', 'date', 'author', 'id', 'num_comments', \n",
    "                 'score', 'text', 'link_flair_text']]\n",
    "\n",
    "        # Print how many flairs are empty and the percentage\n",
    "        print(\"Number of empty flairs:\", len(df[df['link_flair_text'] == \"\"]))\n",
    "        print(\"Percentage of empty flairs:\",\n",
    "              len(df[df['link_flair_text'] == \"\"])/len(df.index))\n",
    "\n",
    "        # Print number of unique authors\n",
    "        print(\"Number of unique authors\", len(df.author.unique()))\n",
    "\n",
    "        # Display and print size\n",
    "        print(df.head())\n",
    "        print(len(df.index))\n",
    "\n",
    "        # Save to csv with subreddit name and year\n",
    "        df.to_csv(\"./clean_data/clean_{}_{}_submission_data.csv\".format(df['subreddit'][0],\n",
    "                                                                        f[-8:-4]),\n",
    "                  index=False)\n",
    "    except:\n",
    "        print(\"The file you are trying to read either does not exist or is missing a column.\\n\" +\n",
    "              \"The columns are: id, author, created_utc, link_flair_text, num_comments,\" +\n",
    "              \"score, selftext, subreddit, title, total_awards_received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d45bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./raw_data/ADHD_post_data_2019.csv', './raw_data/ADHD_post_data_2020.csv', './raw_data/anxiety_post_data_2019.csv', './raw_data/anxiety_post_data_2020.csv', './raw_data/depression_help_post_data_2020.csv', './raw_data/mentalhealth_post_data_L3YR.csv', './raw_data/overcoming_post_data_2020.csv', './raw_data/sad_post_data_2019.csv', './raw_data/sad_post_data_2020.csv']\n"
     ]
    }
   ],
   "source": [
    "# If the clean_data forlder does not exist, create it\n",
    "if not os.path.exists(\"./clean_data/\"):\n",
    "    os.mkdir(\"./clean_data/\")\n",
    "\n",
    "# Read the CSV files into a list\n",
    "try:\n",
    "    # List of csv files\n",
    "    csvs = [f.name for f in os.scandir(\"./raw_data/\") if f.name.endswith(\".csv\")]\n",
    "    \n",
    "    # Remove hidden directories\n",
    "    csvs = [f for f in csvs if not f.startswith('.')]\n",
    "    \n",
    "    # Append directory as prefix to strings in list\n",
    "    csvs = ['./raw_data/' + f for f in csvs]\n",
    "    \n",
    "    print(csvs)\n",
    "except:\n",
    "    print(\"The raw_data folder does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707fc009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/ADHD_post_data_2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denni\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (10,37,74) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total awards = 0: 38184\n",
      "Percentage of total awards = 0: 1.0\n",
      "Number of empty flairs: 28313\n",
      "Percentage of empty flairs: 0.7414885816048606\n",
      "Number of unique authors 21790\n",
      "  subreddit        date                author      id  num_comments score  \\\n",
      "0      ADHD  01/01/2019         DirtJunkie133  abd11x          13.0     1   \n",
      "1      ADHD  01/01/2019  Lin_the_pillow_artis  abd7q9           5.0     1   \n",
      "2      ADHD  01/01/2019         Fleetfeathers  abda0t          12.0     1   \n",
      "3      ADHD  01/01/2019         UnleashedDebs  abdd13           4.0     1   \n",
      "4      ADHD  01/01/2019              liluglee  abdj4w           1.0     1   \n",
      "\n",
      "                                                text link_flair_text  \n",
      "0  Recently diagnosed, need to talk to others who...                  \n",
      "1  Really annoyed at my familys drunk friends So ...                  \n",
      "2  The medication journey: a current disappointme...                  \n",
      "3  Wearables, REM sleep detected while gaming not...                  \n",
      "4  Picking a friend up to carpool to a NYE party....                  \n",
      "38184\n",
      "./raw_data/ADHD_post_data_2020.csv\n",
      "Number of total awards = 0: 75734\n",
      "Percentage of total awards = 0: 0.9986549923519173\n",
      "Number of empty flairs: 35162\n",
      "Percentage of empty flairs: 0.46365842080278497\n",
      "Number of unique authors 42338\n",
      "  subreddit        date         author      id  num_comments  score  \\\n",
      "0      ADHD  01/01/2020       grizgurl  eib0qy             6      1   \n",
      "1      ADHD  01/01/2020        omgboat  eib7y6             6      1   \n",
      "2      ADHD  01/01/2020   buxtonwater3  eibg1t             1      1   \n",
      "3      ADHD  01/01/2020  FastDatabase3  eibg74             2      1   \n",
      "4      ADHD  01/01/2020    Shrewcifer2  eibgft             2      1   \n",
      "\n",
      "                                                text      link_flair_text  \n",
      "0  What’s helped you since dx? Since receiving my...     Tips/Suggestions  \n",
      "1  Discharged from GP I have seen the same GP for...                       \n",
      "2  Guess who missed the start of the new decade b...  Success/Celebration  \n",
      "3  If ADHD delays prefrontal cortex development, ...                       \n",
      "4  Executive function and medication TLDR: has me...                       \n",
      "75836\n",
      "./raw_data/anxiety_post_data_2019.csv\n",
      "Number of total awards = 0: 57983\n",
      "Percentage of total awards = 0: 1.0\n",
      "Number of empty flairs: 29025\n",
      "Percentage of empty flairs: 0.5005777555490403\n",
      "Number of unique authors 37468\n",
      "  subreddit        date             author      id  num_comments  score  \\\n",
      "0   Anxiety  01/01/2019     cakesovernoods  abcvvq             7      1   \n",
      "1   Anxiety  01/01/2019  itsfredericklamar  abcxeh            16      1   \n",
      "2   Anxiety  01/01/2019           jpegjade  abcylm             4      1   \n",
      "3   Anxiety  01/01/2019       Layne_Cobain  abd0ff             4      1   \n",
      "4   Anxiety  01/01/2019          sio_later  abd1m3             5      1   \n",
      "\n",
      "                                                text link_flair_text  \n",
      "0  Anxiety-Depressions meds and the effects. I am...      Medication  \n",
      "1  Paxil side effects? I’ve been taking 20mg Paxi...                  \n",
      "2  Birdbox set my progress back more than I reali...                  \n",
      "3  Anyone else’s anxiety manifest with weird phys...   DAE Questions  \n",
      "4  Tight chest, especially at night Few days ago ...   Advice Needed  \n",
      "57983\n",
      "./raw_data/anxiety_post_data_2020.csv\n",
      "Number of total awards = 0: 72122\n",
      "Percentage of total awards = 0: 0.9990026872039227\n",
      "Number of empty flairs: 26041\n",
      "Percentage of empty flairs: 0.36070864614787934\n",
      "Number of unique authors 45822\n",
      "  subreddit        date          author      id  num_comments  score  \\\n",
      "0   Anxiety  01/01/2020  Single_gay_mom  eib1fl             0      1   \n",
      "1   Anxiety  01/01/2020    StormRider21  eib34y             1      1   \n",
      "2   Anxiety  01/01/2020           -zzzz  eib4y4             0      1   \n",
      "3   Anxiety  01/01/2020          Rikc16  eib6ym             0      1   \n",
      "4   Anxiety  01/01/2020      wolksvagon  eibbse             4      1   \n",
      "\n",
      "                                                text      link_flair_text  \n",
      "0  Started out my New Years with bailing on a par...                       \n",
      "1  Fireworks give me anxiety and it's new year, g...                       \n",
      "2  Have been gagging all day, but have no food in...               Health  \n",
      "3  Happy new year everyone! Here’s hoping we all ...                       \n",
      "4  Need advice on how I can help my wife. Hello m...  Needs A Hug/Support  \n",
      "72194\n",
      "./raw_data/depression_help_post_data_2020.csv\n",
      "Number of total awards = 0: 11922\n",
      "Percentage of total awards = 0: 0.9993294216261526\n",
      "Number of empty flairs: 873\n",
      "Percentage of empty flairs: 0.07317686504610227\n",
      "Number of unique authors 8633\n",
      "         subreddit        date               author      id  num_comments  \\\n",
      "0  depression_help  01/01/2020      gameisnotoversa  eibwej            16   \n",
      "1  depression_help  01/01/2020            jduncan93  eic340             4   \n",
      "2  depression_help  01/01/2020       verticalmisfit  eic62w            16   \n",
      "3  depression_help  01/01/2020               Vaeuio  eic7ar             8   \n",
      "4  depression_help  01/01/2020  nothingimportant___  eidi8d             7   \n",
      "\n",
      "   score                                               text    link_flair_text  \n",
      "0      1  ‪Maybe this year wasn’t the best, but look at ...        INSPIRATION  \n",
      "1      1  I need help for relationships i desperately ne...  REQUESTING ADVICE  \n",
      "2      1  Does anyone else feel like they finally want t...                     \n",
      "3      1  I’m 16 and I’m having trouble with life For th...                     \n",
      "4      1  Lifes breaking apart, i can't feel things norm...                     \n",
      "11930\n",
      "./raw_data/mentalhealth_post_data_L3YR.csv\n",
      "Number of total awards = 0: 221245\n",
      "Percentage of total awards = 0: 0.9984520822427208\n",
      "Number of empty flairs: 142331\n",
      "Percentage of empty flairs: 0.6423226889542755\n",
      "Number of unique authors 140576\n",
      "      subreddit        date       author      id  num_comments  score  \\\n",
      "0  mentalhealth  01/01/2018  neurolonnet  7nebqv             0      1   \n",
      "1  mentalhealth  01/01/2018      netches  7nef8w             4      0   \n",
      "2  mentalhealth  01/01/2018     adammiln  7nejf6             0      0   \n",
      "3  mentalhealth  01/01/2018    Valkyria6  7nejua             1      1   \n",
      "4  mentalhealth  01/01/2018    Sarahlump  7nem8y             4      1   \n",
      "\n",
      "                                                text link_flair_text  \n",
      "0                     2 x Neurolon Brain Supplement                   \n",
      "1  Am I even sick enough to justify going to hosp...                  \n",
      "2  How To Relax Your Mind | Easy Method To Relax ...                  \n",
      "3  Sudden feeling of deep disgust at random times...                  \n",
      "4  Im strugglimg with loneliness I have 0 humans ...                  \n",
      "221588\n",
      "./raw_data/overcoming_post_data_2020.csv\n",
      "Number of total awards = 0: 1179\n",
      "Percentage of total awards = 0: 1.0\n",
      "Number of empty flairs: 76\n",
      "Percentage of empty flairs: 0.06446140797285835\n",
      "Number of unique authors 550\n",
      "    subreddit        date             author      id  num_comments  score  \\\n",
      "0  overcoming  01/01/2020     autumndawn1996  eie5od             7      1   \n",
      "1  overcoming  01/01/2020           TonyWazz  eig8dy             1      1   \n",
      "2  overcoming  02/01/2020     Comrade_Chadek  eiu5dl            22      1   \n",
      "3  overcoming  03/01/2020   waffleking333333  ej799i             6      2   \n",
      "4  overcoming  03/01/2020  path02inspiration  ej841p             2      1   \n",
      "\n",
      "                                                text    link_flair_text  \n",
      "0      After a week, I finally finished my room. :)          MOTIVATION  \n",
      "1  Goodbye 2019   \\n\\nGood bye 2019.\\n\\nHow did a...              STORY  \n",
      "2  Is it okay if I don't get a girlfriend? I've t...  REQUESTING ADVICE  \n",
      "3  Why is this happening to me? Just for some bac...  REQUESTING ADVICE  \n",
      "4                             The Fearless Attitude          MOTIVATION  \n",
      "1179\n",
      "./raw_data/sad_post_data_2019.csv\n",
      "The file you are trying to read either does not exist or is missing a column.\n",
      "The columns are: id, author, created_utc, link_flair_text, num_comments,score, selftext, subreddit, title, total_awards_received\n",
      "./raw_data/sad_post_data_2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denni\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3364: DtypeWarning: Columns (83) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total awards = 0: 13142\n",
      "Percentage of total awards = 0: 0.9901303397875386\n",
      "Number of empty flairs: 12869\n",
      "Percentage of empty flairs: 0.9695622692684397\n",
      "Number of unique authors 9940\n",
      "  subreddit        date          author      id  num_comments  score  \\\n",
      "0       sad  01/01/2020  xXBleachlessXx  eib72q             1      1   \n",
      "1       sad  01/01/2020  RogueGamerFoxx  eib8nq             2      1   \n",
      "2       sad  01/01/2020          wocka3  eibgli             0      1   \n",
      "3       sad  01/01/2020  bobthebillyman  eibu9r             3      1   \n",
      "4       sad  01/01/2020  TheWeebWalking  eibuvy             5      1   \n",
      "\n",
      "                                                text link_flair_text  \n",
      "0  The Last Hug It was the day. The day she had b...                  \n",
      "1  New Years Blues I so much want to feel optimis...                  \n",
      "2  It’s been 14 days I made a commitment, unfortu...                  \n",
      "3  New year🙃 At midnight I text my gf a really he...                  \n",
      "4    The memes will never be forgotten 2️⃣0️⃣2️⃣0️⃣                   \n",
      "13273\n"
     ]
    }
   ],
   "source": [
    "# Apply basic preprocessing to each csv file\n",
    "for c in csvs:\n",
    "    print(c)\n",
    "    basic_data_preproc(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338fc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
