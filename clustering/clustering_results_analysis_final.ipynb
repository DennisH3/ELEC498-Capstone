{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93097f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1649e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>bow_kmeans_label</th>\n",
       "      <th>bow_birch_label</th>\n",
       "      <th>bow_hdbscan_label</th>\n",
       "      <th>d2v_kmeans_label</th>\n",
       "      <th>d2v_birch_label</th>\n",
       "      <th>d2v_hdbscan_label</th>\n",
       "      <th>df_copy_kmeans_label</th>\n",
       "      <th>df_copy_birch_label</th>\n",
       "      <th>df_copy_hdbscan_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l4q8j5</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>feel le depressed empty inside right happy im...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lxdqv0</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>depression ive dealing stuff idk call put lab...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e0plue</td>\n",
       "      <td>happy</td>\n",
       "      <td>finally fixed car took one day two week second...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j3jv3k</td>\n",
       "      <td>depression_help</td>\n",
       "      <td>help depressed little sister doesnt tell anyt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ksbtnt</td>\n",
       "      <td>CasualConversation</td>\n",
       "      <td>got first job ever finally pay family rent go...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id           subreddit  \\\n",
       "0  l4q8j5        mentalhealth   \n",
       "1  lxdqv0        mentalhealth   \n",
       "2  e0plue               happy   \n",
       "3  j3jv3k     depression_help   \n",
       "4  ksbtnt  CasualConversation   \n",
       "\n",
       "                                          clean_text  label  bow_kmeans_label  \\\n",
       "0   feel le depressed empty inside right happy im...      1                 1   \n",
       "1   depression ive dealing stuff idk call put lab...      1                 0   \n",
       "2  finally fixed car took one day two week second...      0                 1   \n",
       "3   help depressed little sister doesnt tell anyt...      1                 0   \n",
       "4   got first job ever finally pay family rent go...      0                 1   \n",
       "\n",
       "   bow_birch_label  bow_hdbscan_label  d2v_kmeans_label  d2v_birch_label  \\\n",
       "0                1                  0                 0                0   \n",
       "1                1                  0                 1                0   \n",
       "2                1                  0                 0                0   \n",
       "3                0                  0                 1                0   \n",
       "4                1                  0                 0                0   \n",
       "\n",
       "   d2v_hdbscan_label  df_copy_kmeans_label  df_copy_birch_label  \\\n",
       "0                  0                     0                    0   \n",
       "1                  0                     1                    0   \n",
       "2                  0                     0                    0   \n",
       "3                  0                     1                    1   \n",
       "4                  0                     0                    0   \n",
       "\n",
       "   df_copy_hdbscan_label  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"./preproc_data/clustered_BoW_d2v_final.csv\")\n",
    "\n",
    "# Print length\n",
    "print(len(df.index))\n",
    "\n",
    "# Check\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c9d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we don't know which clustered group matches with our label,\n",
    "# we need to also flip the clustered label and compare with label\n",
    "# It is faster to flip our label than to flip multiple columns\n",
    "# In the first pass, we will treat label=1 as depressive and \n",
    "# label=0 as non-depressive, then label=1 as non-depressive and\n",
    "# label=0 as depressive\n",
    "df['flip_label'] = (~df['label'].astype(bool)).astype(int)\n",
    "\n",
    "# Increment all hdbscan_labels (since the range for their labels was [-1, 0])\n",
    "df['bow_hdbscan_label'] = df['bow_hdbscan_label'] + 1\n",
    "df['d2v_hdbscan_label'] = df['d2v_hdbscan_label'] + 1\n",
    "df['df_copy_hdbscan_label'] = df['df_copy_hdbscan_label'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73d54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because classification models only predicted on test data,\n",
    "# We need to filter the results for only the test data rows\n",
    "test = pd.read_csv(\"./train_test_data/test_data.csv\", low_memory=False)\n",
    "\n",
    "# Select all columns that are numerical\n",
    "test_nums = test.select_dtypes(['number'])\n",
    "\n",
    "# Drop NaNs\n",
    "test_nums = test_nums.dropna()\n",
    "\n",
    "# Filter out rows that were dropped\n",
    "test = test[test[\"index\"].isin(test_nums[\"index\"])]\n",
    "\n",
    "# Filter the results for only the test data rows\n",
    "df = df[df[\"id\"].isin(test[\"id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18a3d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for kmeans\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_kmeans_label is: 0.28680073345958457\n",
      "Accuracy score between label and d2v_kmeans_label is: 0.8129678059338082\n",
      "Accuracy score between label and df_copy_kmeans_label is: 0.7588000120239277\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_kmeans_label is: 0.3300742870836329\n",
      "Precision score between label and d2v_kmeans_label is: 0.8304665185655348\n",
      "Precision score between label and df_copy_kmeans_label is: 0.8237461463267914\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_kmeans_label is: 0.41400661256387133\n",
      "Recall score between label and d2v_kmeans_label is: 0.7865344153892395\n",
      "Recall score between label and df_copy_kmeans_label is: 0.658551247370003\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_kmeans_label is: 0.36730666666666667\n",
      "F1 score between label and d2v_kmeans_label is: 0.8079036739734485\n",
      "F1 score between label and df_copy_kmeans_label is: 0.7319436092737356\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for kmeans for dif features\n",
    "print(\"Classification metrics for kmeans\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_kmeans_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4b3af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for birch\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_birch_label is: 0.4299756515465777\n",
      "Accuracy score between label and d2v_birch_label is: 0.5028406528992695\n",
      "Accuracy score between label and df_copy_birch_label is: 0.575825893528121\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_birch_label is: 0.4615104821109715\n",
      "Precision score between label and d2v_birch_label is: 0.9363636363636364\n",
      "Precision score between label and df_copy_birch_label is: 0.8603655054254712\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_birch_label is: 0.8390141268409979\n",
      "Recall score between label and d2v_birch_label is: 0.006191764352269312\n",
      "Recall score between label and df_copy_birch_label is: 0.18112413585813045\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_birch_label is: 0.5954732598075816\n",
      "F1 score between label and d2v_birch_label is: 0.01230217975515079\n",
      "F1 score between label and df_copy_birch_label is: 0.2992501365645329\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for birch for dif features\n",
    "print(\"Classification metrics for birch\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_birch_label is:\", \n",
    "      precision_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_birch_label is:\", \n",
    "      precision_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_birch_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_birch_label is:\", \n",
    "      recall_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_birch_label is:\", \n",
    "      recall_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_birch_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_birch_label is:\", \n",
    "      f1_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_birch_label is:\", \n",
    "      f1_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_birch_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_birch_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806802f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for hdbscan\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_hdbscan_label is: 0.44861273935130913\n",
      "Accuracy score between label and d2v_hdbscan_label is: 0.4856163765894129\n",
      "Accuracy score between label and df_copy_hdbscan_label is: 0.4661376138515646\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_hdbscan_label is: 0.4705415660572611\n",
      "Precision score between label and d2v_hdbscan_label is: 0.49230620342591697\n",
      "Precision score between label and df_copy_hdbscan_label is: 0.48164464023494863\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_hdbscan_label is: 0.8200180342651037\n",
      "Recall score between label and d2v_hdbscan_label is: 0.9174030658250676\n",
      "Recall score between label and df_copy_hdbscan_label is: 0.8872858431018936\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_hdbscan_label is: 0.5979616438356165\n",
      "F1 score between label and d2v_hdbscan_label is: 0.6407608011084519\n",
      "F1 score between label and df_copy_hdbscan_label is: 0.6243654822335025\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for hdbscan for dif features\n",
    "print(\"Classification metrics for hdbscan\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_hdbscan_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba86894",
   "metadata": {},
   "source": [
    "# Compare with Flip Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401308a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for kmeans\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_kmeans_label is: 0.7131992665404154\n",
      "Accuracy score between flip_label and d2v_kmeans_label is: 0.18703219406619173\n",
      "Accuracy score between flip_label and df_copy_kmeans_label is: 0.2411999879760724\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_kmeans_label is: 0.6699257129163672\n",
      "Precision score between flip_label and d2v_kmeans_label is: 0.16953348143446526\n",
      "Precision score between flip_label and df_copy_kmeans_label is: 0.1762538536732085\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_kmeans_label is: 0.8404280904280904\n",
      "Recall score between flip_label and d2v_kmeans_label is: 0.1605940355940356\n",
      "Recall score between flip_label and df_copy_kmeans_label is: 0.14093314093314094\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_kmeans_label is: 0.745552977571539\n",
      "F1 score between label and d2v_kmeans_label is: 0.16494272393244205\n",
      "F1 score between label and df_copy_kmeans_label is: 0.15662690855634626\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for kmeans for dif features\n",
    "print(\"Classification metrics for kmeans\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['df_copy_kmeans_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd52be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for birch\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_birch_label is: 0.5700243484534223\n",
      "Accuracy score between flip_label and d2v_birch_label is: 0.49715934710073045\n",
      "Accuracy score between flip_label and df_copy_birch_label is: 0.42417410647187903\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_birch_label is: 0.5384895178890285\n",
      "Precision score between flip_label and d2v_birch_label is: 0.06363636363636363\n",
      "Precision score between flip_label and df_copy_birch_label is: 0.13963449457452884\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_birch_label is: 0.9791366041366041\n",
      "Recall score between flip_label and d2v_birch_label is: 0.00042087542087542086\n",
      "Recall score between flip_label and df_copy_birch_label is: 0.0294011544011544\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_birch_label is: 0.6948414899517856\n",
      "F1 score between label and d2v_birch_label is: 0.0008362202843148966\n",
      "F1 score between label and df_copy_birch_label is: 0.04857455051157246\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for birch for dif features\n",
    "print(\"Classification metrics for birch\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['df_copy_birch_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6024ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for hdbscan\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_hdbscan_label is: 0.5513872606486909\n",
      "Accuracy score between flip_label and d2v_hdbscan_label is: 0.5143836234105871\n",
      "Accuracy score between flip_label and df_copy_hdbscan_label is: 0.5338623861484354\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_hdbscan_label is: 0.5294584339427388\n",
      "Precision score between flip_label and d2v_hdbscan_label is: 0.5076937965740831\n",
      "Precision score between flip_label and df_copy_hdbscan_label is: 0.5183553597650514\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_hdbscan_label is: 0.9228595478595478\n",
      "Recall score between flip_label and d2v_hdbscan_label is: 0.9462481962481962\n",
      "Recall score between flip_label and df_copy_hdbscan_label is: 0.9550865800865801\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_hdbscan_label is: 0.6728771206873877\n",
      "F1 score between label and d2v_hdbscan_label is: 0.6608301316369591\n",
      "F1 score between label and df_copy_hdbscan_label is: 0.6719969541214544\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for hdbscan for dif features\n",
    "print(\"Classification metrics for hdbscan\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_hdbscan_label is:\", \n",
    "      f1_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_hdbscan_label is:\", \n",
    "      f1_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_hdbscan_label is:\", \n",
    "      f1_score(df['flip_label'], df['df_copy_hdbscan_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377f95c",
   "metadata": {},
   "source": [
    "# Results with All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e0ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset df\n",
    "df = pd.read_csv(\"./preproc_data/clustered_BoW_d2v_final.csv\")\n",
    "\n",
    "# Because we don't know which clustered group matches with our label,\n",
    "# we need to also flip the clustered label and compare with label\n",
    "# It is faster to flip our label than to flip multiple columns\n",
    "# In the first pass, we will treat label=1 as depressive and \n",
    "# label=0 as non-depressive, then label=1 as non-depressive and\n",
    "# label=0 as depressive\n",
    "df['flip_label'] = (~df['label'].astype(bool)).astype(int)\n",
    "\n",
    "# Increment all hdbscan_labels (since the range for their labels was [-1, 0])\n",
    "df['bow_hdbscan_label'] = df['bow_hdbscan_label'] + 1\n",
    "df['d2v_hdbscan_label'] = df['d2v_hdbscan_label'] + 1\n",
    "df['df_copy_hdbscan_label'] = df['df_copy_hdbscan_label'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29af657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for kmeans\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_kmeans_label is: 0.2835122819251903\n",
      "Accuracy score between label and d2v_kmeans_label is: 0.8161919419028267\n",
      "Accuracy score between label and df_copy_kmeans_label is: 0.7619302401077298\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_kmeans_label is: 0.3263503086419753\n",
      "Precision score between label and d2v_kmeans_label is: 0.835619759829507\n",
      "Precision score between label and df_copy_kmeans_label is: 0.8239098437430309\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_kmeans_label is: 0.40680982037656\n",
      "Recall score between label and d2v_kmeans_label is: 0.7872652511602183\n",
      "Recall score between label and df_copy_kmeans_label is: 0.6662779233895207\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_kmeans_label is: 0.36216511286887093\n",
      "F1 score between label and d2v_kmeans_label is: 0.8107221345219302\n",
      "F1 score between label and df_copy_kmeans_label is: 0.7367567387908399\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for kmeans for dif features\n",
    "print(\"Classification metrics for kmeans\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_kmeans_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_kmeans_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_kmeans_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_kmeans_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_kmeans_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da33ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for birch\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_birch_label is: 0.43031224825960973\n",
      "Accuracy score between label and d2v_birch_label is: 0.5025429536737565\n",
      "Accuracy score between label and df_copy_birch_label is: 0.5785670486106936\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_birch_label is: 0.4616601052039567\n",
      "Precision score between label and d2v_birch_label is: 0.9400826446280992\n",
      "Precision score between label and df_copy_birch_label is: 0.8632321885072802\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_birch_label is: 0.8388799384423017\n",
      "Recall score between label and d2v_birch_label is: 0.005470459518599562\n",
      "Recall score between label and df_copy_birch_label is: 0.186753071873422\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_birch_label is: 0.5955639774827258\n",
      "F1 score between label and d2v_birch_label is: 0.01087762078940448\n",
      "F1 score between label and df_copy_birch_label is: 0.3070733828878697\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for birch for dif features\n",
    "print(\"Classification metrics for birch\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_birch_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_birch_label is:\", \n",
    "      precision_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_birch_label is:\", \n",
    "      precision_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_birch_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_birch_label is:\", \n",
    "      recall_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_birch_label is:\", \n",
    "      recall_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_birch_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_birch_label is:\", \n",
    "      f1_score(df['label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_birch_label is:\", \n",
    "      f1_score(df['label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_birch_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_birch_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c21bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for hdbscan\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between label and bow_hdbscan_label is: 0.4493152661384377\n",
      "Accuracy score between label and d2v_hdbscan_label is: 0.485565882338796\n",
      "Accuracy score between label and df_copy_hdbscan_label is: 0.46623222036527157\n",
      "\n",
      "Precision\n",
      "Precision score between label and bow_hdbscan_label is: 0.4708821050013129\n",
      "Precision score between label and d2v_hdbscan_label is: 0.49226321834630327\n",
      "Precision score between label and df_copy_hdbscan_label is: 0.4816926026896938\n",
      "\n",
      "Recall\n",
      "Recall score between label and bow_hdbscan_label is: 0.8193305600307789\n",
      "Recall score between label and d2v_hdbscan_label is: 0.9172097049558756\n",
      "Recall score between label and df_copy_hdbscan_label is: 0.8879697982542621\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_hdbscan_label is: 0.5980534980868466\n",
      "F1 score between label and d2v_hdbscan_label is: 0.6406772259267347\n",
      "F1 score between label and df_copy_hdbscan_label is: 0.6245750528541226\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for hdbscan for dif features\n",
    "print(\"Classification metrics for hdbscan\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between label and bow_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between label and d2v_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between label and df_copy_hdbscan_label is:\", \n",
    "      accuracy_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between label and bow_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between label and d2v_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between label and df_copy_hdbscan_label is:\", \n",
    "      precision_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between label and bow_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between label and d2v_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between label and df_copy_hdbscan_label is:\", \n",
    "      recall_score(df['label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_hdbscan_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dec1f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for kmeans\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_kmeans_label is: 0.7164877180748097\n",
      "Accuracy score between flip_label and d2v_kmeans_label is: 0.1838080580971733\n",
      "Accuracy score between flip_label and df_copy_kmeans_label is: 0.23806975989227014\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_kmeans_label is: 0.6736496913580247\n",
      "Precision score between flip_label and d2v_kmeans_label is: 0.16438024017049296\n",
      "Precision score between flip_label and df_copy_kmeans_label is: 0.1760901562569691\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_kmeans_label is: 0.839794151596768\n",
      "Recall score between flip_label and d2v_kmeans_label is: 0.1548792804924971\n",
      "Recall score between flip_label and df_copy_kmeans_label is: 0.14241054251635243\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_kmeans_label is: 0.747602329165953\n",
      "F1 score between label and d2v_kmeans_label is: 0.15948838908183668\n",
      "F1 score between label and df_copy_kmeans_label is: 0.15746963683864146\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for kmeans for dif features\n",
    "print(\"Classification metrics for kmeans\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_kmeans_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_kmeans_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_kmeans_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_kmeans_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['bow_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['d2v_kmeans_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_kmeans_label is:\", \n",
    "      f1_score(df['flip_label'], df['df_copy_kmeans_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5553705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for birch\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_birch_label is: 0.5696877517403903\n",
      "Accuracy score between flip_label and d2v_birch_label is: 0.49745704632624355\n",
      "Accuracy score between flip_label and df_copy_birch_label is: 0.42143295138930637\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_birch_label is: 0.5383398947960433\n",
      "Precision score between flip_label and d2v_birch_label is: 0.05991735537190083\n",
      "Precision score between flip_label and df_copy_birch_label is: 0.1367678114927198\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_birch_label is: 0.9782849172758753\n",
      "Recall score between flip_label and d2v_birch_label is: 0.00034869180454020777\n",
      "Recall score between flip_label and df_copy_birch_label is: 0.02959070796460177\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_birch_label is: 0.6945024178094178\n",
      "F1 score between label and d2v_birch_label is: 0.0006933486348204466\n",
      "F1 score between label and df_copy_birch_label is: 0.04865463316265001\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for birch for dif features\n",
    "print(\"Classification metrics for birch\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_birch_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_birch_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_birch_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_birch_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['bow_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['d2v_birch_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_birch_label is:\", \n",
    "      f1_score(df['flip_label'], df['df_copy_birch_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9718d107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification metrics for hdbscan\n",
      "\n",
      "Prediction Accuracy\n",
      "Accuracy score between flip_label and bow_hdbscan_label is: 0.5506847338615624\n",
      "Accuracy score between flip_label and d2v_hdbscan_label is: 0.5144341176612041\n",
      "Accuracy score between flip_label and df_copy_hdbscan_label is: 0.5337677796347284\n",
      "\n",
      "Precision\n",
      "Precision score between flip_label and bow_hdbscan_label is: 0.5291178949986871\n",
      "Precision score between flip_label and d2v_hdbscan_label is: 0.5077367816536967\n",
      "Precision score between flip_label and df_copy_hdbscan_label is: 0.5183073973103062\n",
      "\n",
      "Recall\n",
      "Recall score between flip_label and bow_hdbscan_label is: 0.9207267218160831\n",
      "Recall score between flip_label and d2v_hdbscan_label is: 0.9461090804155444\n",
      "Recall score between flip_label and df_copy_hdbscan_label is: 0.955535782993459\n",
      "\n",
      "F1\n",
      "F1 score between label and bow_hdbscan_label is: 0.5980534980868466\n",
      "F1 score between label and d2v_hdbscan_label is: 0.6406772259267347\n",
      "F1 score between label and df_copy_hdbscan_label is: 0.6245750528541226\n"
     ]
    }
   ],
   "source": [
    "# Comparison of metrics for hdbscan for dif features\n",
    "print(\"Classification metrics for hdbscan\")\n",
    "print(\"\\nPrediction Accuracy\")\n",
    "print(\"Accuracy score between flip_label and bow_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and d2v_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Accuracy score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      accuracy_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nPrecision\")\n",
    "print(\"Precision score between flip_label and bow_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and d2v_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Precision score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      precision_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\"Recall score between flip_label and bow_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and d2v_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"Recall score between flip_label and df_copy_hdbscan_label is:\", \n",
    "      recall_score(df['flip_label'], df['df_copy_hdbscan_label']))\n",
    "\n",
    "print(\"\\nF1\")\n",
    "print(\"F1 score between label and bow_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['bow_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and d2v_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['d2v_hdbscan_label']))\n",
    "\n",
    "print(\"F1 score between label and df_copy_hdbscan_label is:\", \n",
    "      f1_score(df['label'], df['df_copy_hdbscan_label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
